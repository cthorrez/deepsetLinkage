epoch: 0 train loss: 3.936099370320638
epoch: 0 val loss: 3.900634905008169
epoch: 1 train loss: 3.753554344177246
epoch: 1 val loss: 3.696267063157258
epoch: 2 train loss: 3.461308320363363
epoch: 2 val loss: 3.3336742534607535
epoch: 3 train loss: 2.9549010594685874
epoch: 3 val loss: 2.649950014273456
epoch: 4 train loss: 2.0735614697138467
epoch: 4 val loss: 1.831602337145116
epoch: 5 train loss: 1.3252655665079753
epoch: 5 val loss: 1.2877112059842286
epoch: 6 train loss: 0.9164406259854635
epoch: 6 val loss: 0.9582137073784969
epoch: 7 train loss: 0.7307515541712443
epoch: 7 val loss: 0.7557289147860307
epoch: 8 train loss: 0.5878433585166931
epoch: 8 val loss: 0.6363995596447394
epoch: 9 train loss: 0.6001193324724833
epoch: 9 val loss: 0.6209698416593454
train loss went up, stopping now
blum_a best f1: 0.9844609132201769 best link: 1.7832152843475342
young_s best f1: 0.6149280986076238 best link: -3.8224480152130127
best threshold: 1.7833117277324497
31 data points
23 merged performed
test f1 on robinson_h: 0.6478873239436619
72 data points
56 merged performed
test f1 on allen_d: 0.11392405063291139
227 data points
210 merged performed
test f1 on moore_a: 0.6967496130491725
test f1: 0.48618699587524866

real	20m42.871s
user	19m28.343s
sys	1m14.984s
