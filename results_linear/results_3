epoch: 0 train loss: 3.9118537108103433
epoch: 0 val loss: 3.786618031512678
epoch: 1 train loss: 3.634920517603556
epoch: 1 val loss: 3.5391704660579695
epoch: 2 train loss: 3.363062063852946
epoch: 2 val loss: 3.2602630113730173
epoch: 3 train loss: 3.061511675516764
epoch: 3 val loss: 2.937862070079227
epoch: 4 train loss: 2.715779701868693
epoch: 4 val loss: 2.567574579802143
epoch: 5 train loss: 2.3907605012257895
epoch: 5 val loss: 2.217696203249803
epoch: 6 train loss: 2.0758513609568277
epoch: 6 val loss: 1.917134567869432
epoch: 7 train loss: 1.8002245823542278
epoch: 7 val loss: 1.6715585570372928
epoch: 8 train loss: 1.5818448861440022
epoch: 8 val loss: 1.5126153161141642
epoch: 9 train loss: 1.3866068522135417
epoch: 9 val loss: 1.398348407201199
epoch: 10 train loss: 1.2517231702804565
epoch: 10 val loss: 1.3251810064389904
epoch: 11 train loss: 1.1859736442565918
epoch: 11 val loss: 1.2546516004805932
epoch: 12 train loss: 1.1332347790400188
epoch: 12 val loss: 1.161159422932568
epoch: 13 train loss: 1.0898093581199646
epoch: 13 val loss: 1.0584345891484044
epoch: 14 train loss: 1.0339996019999187
epoch: 14 val loss: 0.9666747238594359
epoch: 15 train loss: 0.977750321229299
epoch: 15 val loss: 0.8938583986815984
epoch: 16 train loss: 0.9138581951459249
epoch: 16 val loss: 0.8353349388656176
epoch: 17 train loss: 0.8599632382392883
epoch: 17 val loss: 0.8044328264553439
epoch: 18 train loss: 0.8128961324691772
epoch: 18 val loss: 0.7857487856471868
epoch: 19 train loss: 0.7686519424120585
epoch: 19 val loss: 0.7669721596801805
epoch: 20 train loss: 0.7265392939249674
epoch: 20 val loss: 0.7461923123041275
epoch: 21 train loss: 0.6851363182067871
epoch: 21 val loss: 0.7264970660052499
epoch: 22 train loss: 0.6504787604014078
epoch: 22 val loss: 0.7065560480881874
epoch: 23 train loss: 0.6255214711030325
epoch: 23 val loss: 0.6928006357951084
epoch: 24 train loss: 0.6097679634888967
epoch: 24 val loss: 0.6843913246435348
epoch: 25 train loss: 0.5943837662537893
epoch: 25 val loss: 0.6765542636823022
epoch: 26 train loss: 0.5833040575186411
epoch: 26 val loss: 0.6689928120579869
epoch: 27 train loss: 0.5744405885537466
epoch: 27 val loss: 0.6615141507247003
epoch: 28 train loss: 0.5649990737438202
epoch: 28 val loss: 0.655608640516656
epoch: 29 train loss: 0.5556889673074087
epoch: 29 val loss: 0.6508400528766414
epoch: 30 train loss: 0.5462135970592499
epoch: 30 val loss: 0.6454783496527147
epoch: 31 train loss: 0.5306916038195292
epoch: 31 val loss: 0.6385773879919141
epoch: 32 train loss: 0.5235535701115926
epoch: 32 val loss: 0.63875766624976
epoch: 33 train loss: 0.515093207359314
epoch: 33 val loss: 0.6435916463596015
epoch: 34 train loss: 0.5255949894587199
epoch: 34 val loss: 0.6408265284165757
train loss went up, stopping now
jones_s best f1: 0.8854047810224119 best link: 1.467751145362854
robinson_h best f1: 0.8737864077669902 best link: -1.5993566513061523
blum_a best f1: 0.9793621013133207 best link: 3.138685941696167
young_s best f1: 0.7286649376312214 best link: 1.9049712419509888
mcguire_j best f1: 1.0 best link: 1.6665327548980713
best threshold: 1.8757578878088275
227 data points
209 merged performed
test f1 on moore_a: 0.7310015898251193
72 data points
58 merged performed
test f1 on allen_d: 0.17763157894736842
216 data points
178 merged performed
test f1 on lee_l: 0.7173380035026269
test f1: 0.5419903907583715

real	41m38.594s
user	44m10.922s
sys	0m55.376s
